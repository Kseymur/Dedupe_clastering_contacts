{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4375d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import dj_database_url\n",
    "from psycopg2 import OperationalError\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "from psycopg2.extensions import register_adapter, AsIs\n",
    "\n",
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25aaa13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser():  # класс, который преобразует данные (можно изменить его так, чтобы он мог принимать любые релевантные поля)\n",
    "    def __init__(self):\n",
    "        self.dict_of_values = {'phone': None, 'email': None,\n",
    "                               'created_at': None, 'name': None, 'first_name': None,\n",
    "                               'last_name': None}\n",
    "        self.phone_pattern = re.compile(r\"(\\+7|8|7)[\\s-]?(\\d{3})[\\s-]?(\\d{3})[\\s-]?(\\d{2})[\\s-]?(\\d{2})\")\n",
    "\n",
    "    def get_values(self, data_json):\n",
    "        for el in data_json:\n",
    "            for k, v in el.items():\n",
    "                if type(v) == list:\n",
    "                    self.get_values(v)\n",
    "                else:\n",
    "                    if type(v) == str:\n",
    "                        phone_number = re.findall(self.phone_pattern, v)\n",
    "                        if phone_number:\n",
    "                            self.dict_of_values['phone'] = \"\".join(phone_number[0])\n",
    "                        if '@' in v:\n",
    "                            self.dict_of_values['email'] = v\n",
    "                        if k == 'name' and v:\n",
    "                            self.dict_of_values['name'] = v\n",
    "                        if k == 'first_name' and v:\n",
    "                            self.dict_of_values['first_name'] = v\n",
    "                        if k == 'last_name' and v:\n",
    "                            self.dict_of_values['last_name'] = v\n",
    "                    if type(v) == int:\n",
    "                        if k == 'created_at':\n",
    "                            dt_object = datetime.datetime.fromtimestamp(v)\n",
    "                            formatted_date = dt_object.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                            self.dict_of_values['created_at'] = formatted_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0cae0669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(prompt, valid_values=None, type_=str, min_=None, max_=None, split=False): #функция для проверки корректности ввода\n",
    "    while True:\n",
    "        try:\n",
    "            answer = input(prompt)\n",
    "            if split:\n",
    "                answer = [type_(item.strip()) for item in answer.split(', ')]\n",
    "                for i in answer:\n",
    "                    if valid_values and i not in valid_values:\n",
    "                        raise ValueError(f\"Неверный ввод. Пожалуйста, введите какие-то из следующих значений: {valid_values}\")\n",
    "            else:\n",
    "                answer = type_(answer)\n",
    "                if valid_values and answer not in valid_values:\n",
    "                    raise ValueError(f\"Неверный ввод. Пожалуйста, введите одно из следующих значений: {valid_values}\")\n",
    "                if min_ is not None and answer < min_:\n",
    "                    raise ValueError(f\"Значение не может быть меньше {min_}\")\n",
    "                if max_ is not None and answer > max_:\n",
    "                    raise ValueError(f\"Значение не может быть больше {max_}\")\n",
    "            return answer\n",
    "        except ValueError as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3e3c75d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_high_confidence_clusters_to_db(clusters, data_for_training): #функция для сохранения дублей в базу данных\n",
    "    # Cоздаём словарь с кластерами\n",
    "    cluster_membership = {\n",
    "        record_id: {\"Cluster ID\": cluster_id, \"confidence_score\": score}\n",
    "        for cluster_id, (records, scores) in enumerate(clusters)\n",
    "        for record_id, score in zip(records, scores)\n",
    "    }\n",
    "\n",
    "    # Создание таблицы id-номер кластера\n",
    "    id_with_clusters = {\n",
    "        data_for_training[cluster]['id']: values['Cluster ID']\n",
    "        for cluster, values in cluster_membership.items()\n",
    "    }\n",
    "\n",
    "    # Записываем результаты кластеризации в базу данных\n",
    "    with write_con.cursor() as cur:\n",
    "        cur.execute(\n",
    "            \"SELECT column_name FROM information_schema.columns WHERE table_name = 'base' AND column_name = 'cluster';\")\n",
    "        if not cur.fetchone():\n",
    "            cur.execute(\"ALTER TABLE base ADD COLUMN cluster int;\")\n",
    "        write_con.commit()\n",
    "\n",
    "        for id_value, cluster_value in id_with_clusters.items():\n",
    "            cur.execute(\"UPDATE base SET cluster = %s WHERE id = %s\", (cluster_value, id_value))\n",
    "        write_con.commit()\n",
    "\n",
    "    del cluster_membership, id_with_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dcafd9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_uncertain_pairs(deduper, uncertain_pairs):  # функция предлагает проверить сомнительные объекты\n",
    "    labeled_pairs = []\n",
    "    for pair in uncertain_pairs:\n",
    "        print('\\n', pair[0], '\\n', pair[1])\n",
    "        label = input('Дубли это или нет? (y/n/u). Если хотите прервать дообучение, введите f: ').lower()\n",
    "\n",
    "        if label == 'f':\n",
    "            break\n",
    "        else:\n",
    "            labeled_pairs.append({\"res\": {\"__class__\": \"tuple\", \"__value__\": [pair[0], pair[1]]}, \"label\": label})\n",
    "\n",
    "    return labeled_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a5e4f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs_for_check(clusters, data_for_training, threshold=0.9): # функция получает пары объектов для проверки\n",
    "    pairs_for_check = []\n",
    "    for cluster, scores in clusters:\n",
    "        counter=0\n",
    "        for pair, score in zip(itertools.combinations(cluster, 2), scores):\n",
    "            if score < threshold:\n",
    "                pairs_for_check.append([data_for_training[pair[0]],data_for_training[pair[1]]])\n",
    "    return pairs_for_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "86d48330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_high_confident_clusters(clusters): # функция получает уверенные кластеры\n",
    "    # Создаем список, в который будут добавляться кластеры, у которых для каждого объекта значение принадлежности выше 0.9\n",
    "    result = []\n",
    "\n",
    "# Проходим по каждому элементу\n",
    "    for item in clusters:\n",
    "        if isinstance(item[0], tuple):\n",
    "            if all(score >= 0.9 for score in item[1]):\n",
    "                result.append(item)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "562dce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_low_confident_clusters(clusters): # функция получает неуверенные кластеры\n",
    "    # Создаем список, в который будут добавляться кластеры, у которых для каждого объекта значение принадлежности ниже 0.9\n",
    "    result = []\n",
    "\n",
    "# Проходим по каждому элементу\n",
    "    for item in clusters:\n",
    "        if isinstance(item[0], tuple):\n",
    "            if all(score < 0.9 for score in item[1]):\n",
    "                result.append(item)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ccb9b47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clastering(deduper, data_for_training): # функция для кластеризации и получения новых размеченных данных\n",
    "    confidence_for_clustering = get_input(\n",
    "                \"Для кластеризации введите нижний порог для определения дублей (прим: Это значение от 0 до 1). Если вы хотите охватить больше возможных дублей и затем их проверить, выбирайте порог ниже. Вы можете экспериментировать: \",\n",
    "                type_=float,\n",
    "                min_=0.0,\n",
    "                max_=1.0\n",
    "            )\n",
    "    try:\n",
    "        clusters = deduper.partition(data_for_training, confidence_for_clustering)\n",
    "    except dedupe.core.BlockingError as e:\n",
    "        print(\"Ошибка при кластеризации:\", e)\n",
    "        print(\"Попробуйте разметить данные снова, выбрав другие поля или сменив им приоритеты\")\n",
    "        clusters = None\n",
    "        return False\n",
    "\n",
    "    print(\"Кластеризация завершена\")\n",
    "\n",
    "    high_confident_clusters = get_high_confident_clusters(clusters)\n",
    "    print(\"Уверенные кластеры получены\")\n",
    "    save_high_confidence_clusters_to_db(high_confident_clusters, data_for_training) # сохранение кластеров с уровнем уверенности выше 0.9 в базу данных\n",
    "    print(f\"Сохранили в базу данных\")\n",
    "\n",
    "    user_input = get_input(\n",
    "            \"Продолжить дообучение? (y/n): \",\n",
    "            ['y', 'n']\n",
    "        )\n",
    "    if user_input.lower() == 'n':\n",
    "            # запишем веса модели в файл. Сможем потом благодаря нему использовать модель без обучения\n",
    "        with open(settings_file, 'wb') as sf:\n",
    "            deduper.write_settings(sf)\n",
    "        return False\n",
    "    else:\n",
    "        low_confident_clusters = get_low_confident_clusters(clusters)\n",
    "        pairs_for_check = get_pairs_for_check(low_confident_clusters, data_for_training)\n",
    "        if pairs_for_check:\n",
    "            labeled = label_uncertain_pairs(deduper, pairs_for_check)\n",
    "            # тут мы обновляем training file в соответствии с новыми знаниями\n",
    "            with open(training_file, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "            for i in labeled:\n",
    "                if i[\"label\"] == \"y\":\n",
    "                    data[\"match\"].append(i[\"res\"])\n",
    "                elif i[\"label\"] == \"n\":\n",
    "                    data[\"distinct\"].append(i[\"res\"])\n",
    "\n",
    "                # Сохранение изменений в файле JSON\n",
    "            with open(training_file, \"w\") as file:\n",
    "                json.dump(data, file, ensure_ascii=False, indent=2)\n",
    "            print(\"Поздравляем, вы обновили тренировочные данные\")\n",
    "            answer = get_input(\n",
    "            \"Обновить базу данных новыми кластерами? (y/n): \",\n",
    "            ['y', 'n'])\n",
    "            if answer.lower() == 'y':\n",
    "                del clusters\n",
    "                clastering(deduper, data_for_training)\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            print(\"Дублей не найдено. Вы можете понизить порог кластеризации и попробовать снова\")\n",
    "            answer = get_input(\n",
    "            \"Попробовать снова? (y/n): \",\n",
    "            ['y', 'n'])\n",
    "            if answer.lower() == 'y':\n",
    "                del clusters\n",
    "                clastering(deduper, data_for_training)\n",
    "            else:\n",
    "                return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971e6e7e",
   "metadata": {},
   "source": [
    "Получение контактов из amocrm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "71af7da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = os.getenv('ACCESS_TOKEN')\n",
    "subdomain = os.getenv('SUBDOMAIN')\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {access_token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2793a8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = []\n",
    "page = 0\n",
    "max_page = 100 # тут нужно написать количество страниц с контактами\n",
    "limit = 250 # это количество контактов, отображающееся на одной странице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc6a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "while page<=max_page:\n",
    "    url = f\"https://{subdomain}.amocrm.ru/api/v4/contacts?page={page}&limit={limit}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching contacts: {response.json()}\")\n",
    "        break\n",
    "\n",
    "    part_of_contacts = response.json()\n",
    "    if not part_of_contacts:\n",
    "        break\n",
    "    contacts.extend(part_of_contacts['_embedded'][\"contacts\"])\n",
    "    page += 1\n",
    "    print(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c742c40",
   "metadata": {},
   "source": [
    "Подключение к базе данных и создание таблицы с контактами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f8d1640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read connection to PostgreSQL DB successful\n",
      "Write connection to PostgreSQL DB successful\n"
     ]
    }
   ],
   "source": [
    "os.environ['DATABASE_URL'] = 'postgresql://user_name:password@host:port/db_name'  # задаем адрес для подключения к бд\n",
    "db_conf = dj_database_url.config()  # строки для настройки соединения с базой данных\n",
    "\n",
    "if not db_conf:\n",
    "    raise Exception(\n",
    "       'set DATABASE_URL environment variable with your connection, e.g. '\n",
    "       'export DATABASE_URL=postgres://user:password@host/mydatabase'\n",
    "   )\n",
    "\n",
    "# ниже задаются курсоры для получения данных из базы данных и записи\n",
    "read_con = None\n",
    "write_con = None\n",
    "while not read_con or not write_con:\n",
    "    if not read_con:\n",
    "        try:\n",
    "            read_con = psycopg2.connect(database=db_conf['NAME'],\n",
    "                                       user=db_conf['USER'],\n",
    "                                       password=db_conf['PASSWORD'],\n",
    "                                       host=db_conf['HOST'],\n",
    "                                       cursor_factory=psycopg2.extras.RealDictCursor)\n",
    "            print(\"Read connection to PostgreSQL DB successful\")\n",
    "        except OperationalError as e:\n",
    "            print(f\"The error '{e}' occurred when connecting for reading\")\n",
    "            print(\"Trying to reconnect to the database in 5 seconds\")\n",
    "\n",
    "    if not write_con:\n",
    "        try:\n",
    "            write_con = psycopg2.connect(database=db_conf['NAME'],\n",
    "                                        user=db_conf['USER'],\n",
    "                                        password=db_conf['PASSWORD'],\n",
    "                                        host=db_conf['HOST'])\n",
    "            print(\"Write connection to PostgreSQL DB successful\")\n",
    "        except OperationalError as e:\n",
    "            print(f\"The error '{e}' occurred when connecting for writing\")\n",
    "            print(\"Trying to reconnect to the database in 5 seconds\")\n",
    "\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "29c3aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(contacts)): # находим пример для создания таблицы без None \n",
    "    if not any(value is None for value in contacts[i].values()):\n",
    "        example = contacts[i]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "570ef429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для автоматического создания таблицы\n",
    "with write_con.cursor() as cur:\n",
    "    query = f\"CREATE TABLE IF NOT EXISTS base (\"\n",
    "    for key, value in example.items():\n",
    "        if isinstance(value, bool):\n",
    "            query += f\"{key} boolean, \"\n",
    "        elif isinstance(value, int):\n",
    "            query += f\"{key} bigint, \"\n",
    "        elif isinstance(value, str):\n",
    "            query += f\"{key} text, \"\n",
    "        elif isinstance(value, list):\n",
    "            query += f\"{key} json, \"  # Вы можете использовать другой тип данных для списков, если это необходимо\n",
    "        elif isinstance(value, dict):\n",
    "            query += f\"{key} json, \"\n",
    "            \n",
    "    query = query.rstrip(\", \") + \")\"\n",
    "    cur.execute(query)\n",
    "    write_con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b2f21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для записи в таблицу\n",
    "with write_con.cursor() as cur:\n",
    "    keys = contacts[0].keys()\n",
    "    values = [[json.dumps(dict_[key]) if isinstance(dict_[key], (dict, list)) else dict_[key] for key in keys] for dict_ in contacts]\n",
    "    insert_query = f\"INSERT INTO base ({', '.join(keys)}) VALUES %s\"\n",
    "    psycopg2.extras.execute_values(cur, insert_query, values)\n",
    "    write_con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3bbf447",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = [{'id': contacts[i]['id']} for i in range(len(contacts))] # получам словарь с id объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bda2808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вот так выглядит объект, готовый для обучения модели: \n",
      " {'id': 36496436, 'phone': '+79882350025', 'email': None, 'created_at': '2021-08-26 11:52:53', 'name': 'Виталий', 'first_name': 'Виталий', 'last_name': None}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(id_list)):  # создаём словарь со значениями для обучения\n",
    "    if contacts[i]:\n",
    "        parser = Parser()\n",
    "        parser.get_values([contacts[i]])\n",
    "        id_list[i].update(parser.dict_of_values)\n",
    "    else:\n",
    "        parser = Parser()\n",
    "        id_list[i].update(parser.dict_of_values)\n",
    "\n",
    "data_for_training = {i + 1: v for i, v in enumerate(id_list)}  # получаем итоговое представление данных для обучения\n",
    "\n",
    "print(\"Вот так выглядит объект, готовый для обучения модели: \\n\", data_for_training[1])\n",
    "\n",
    "# удаляем лишние словари и массивы\n",
    "del id_list, contacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a375d7e0",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854a3a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_file = 'test_settings_file'  # это файл с весами, или правилами, модели. Вам его читать не понадобится (и не получится)\n",
    "training_file = 'test_training_file.json'  # это файл с данными разметки. Его мы будем обновлять в процессе дообучения\n",
    "\n",
    "if os.path.exists(settings_file):  # переходим в эту ветку, если уже есть обученная модель и надо просто получить дубликаты\n",
    "answer = get_input(\n",
    "    \"У вас уже обученная модель. Вы хотите найти дубли и занести их в таблицу с её помощью? (y/n): \",\n",
    "    ['y', 'n']\n",
    ")\n",
    "if answer.lower() == 'y':\n",
    "    with open(settings_file, 'rb') as f:\n",
    "        matcher = dedupe.StaticDedupe(f)\n",
    "    confidence_for_clustering = get_input(\n",
    "        \"Введите уровень уверенности для определения дублей (прим: Это значение от 0 до 1. Чем ближе к 1, тем выше точность модели. Рекомендуем использовать 0.9 для записи дублей в бд. Вы можете экспериментировать: \",\n",
    "        type_=float,\n",
    "        min_=0.0,\n",
    "        max_=1.0\n",
    "    )\n",
    "\n",
    "    # Выполнить дедупликацию\n",
    "    duplicates = matcher.partition(data_for_training, confidence_for_clustering)\n",
    "    save_high_confidence_clusters_to_db(duplicates, data_for_training)  # сохранение кластеров с уровнем уверенности выше 0.9 в базу данных\n",
    "    print(f\"Сохранили\")\n",
    "    del duplicates\n",
    "else:\n",
    "    delete_or_not = get_input(\n",
    "    \"Вы хотите удалить файл настроек для модели, чтобы потом обучить ее заново? (y/n): \",\n",
    "    ['y', 'n']\n",
    ")\n",
    "    if delete_or_not.lower() == 'y':\n",
    "        os.remove(settings_file)\n",
    "    else:\n",
    "        print(\"Окей, всего хорошего!\")\n",
    "\n",
    "else:  # переходим в эту ветку, если хотим обучить с нуля или дообучить модель\n",
    "fields = []  # задаем для модели поля, на которых она будет обучаться. Можно выставить приоритеты для полей\n",
    "array_of_fields = get_input(\n",
    "    \"Введите через запятую поля, на которых хотите обучить модель. Например, «phone», «email»: \",\n",
    "    ['phone', 'email', 'created_at'],\n",
    "    split=True\n",
    ")\n",
    "array_of_weights = get_input(\n",
    "    \"Через запятую укажите приоритеты для введённых полей. Например, если особенно важно поле «phone» поставьте ему 2, а «email» — 1. Вводите значения в том же порядке, что в предыдущем шаге: \",\n",
    "    type_=int,\n",
    "    split=True\n",
    ")\n",
    "\n",
    "for field, weight in zip(array_of_fields, array_of_weights):\n",
    "    fields.append({'field': field, 'type': 'String', 'has missing': True, 'weight': weight})\n",
    "\n",
    "deduper = dedupe.Dedupe(fields)  # создаем объект Dedupe, то есть модель, которую будем обучать\n",
    "\n",
    "if os.path.exists(training_file):  # если уже есть какой-то тренировочный файл, то загружаем его без первичного обучения\n",
    "    print('У нас уже есть файл с размеченными экземплярами. Запустим поиск дублей с его помощью ', training_file)\n",
    "    with open(training_file) as tf:\n",
    "        deduper.prepare_training(data_for_training, tf)\n",
    "else:  # если ничего нет, то проводим первичное обучение\n",
    "    print(\"Подождите немного, пока модель готовится к первичной разметке\")\n",
    "    deduper.prepare_training(data_for_training)  # подготавливаем модель к первичной разметке, нужно подождать. Чем\n",
    "    # больше полей было указано для обучения, тем больше времени займет подготовка к обучению\n",
    "    print(\n",
    "        'Сейчас вам нужно будет сравнивать контакты и отвечать на вопрос: дубли это или нет. Введите y, если «да», n, если «нет», u, если вы не уверены. Когда закончите, введите f. PS: оценить стоит хотя бы несколько десятков пар')\n",
    "    dedupe.console_label(deduper)\n",
    "\n",
    "    # запишем результаты активного обучения в файл\n",
    "    with open(training_file, 'w') as tf:\n",
    "        deduper.write_training(tf)\n",
    "\n",
    "print(\"Модель готова к обучению\")\n",
    "deduper.train()  # здесь мы собственно обучаем модель на размеченных данных. может потребоваться какое-то время\n",
    "print(\"Приступаем к кластеризации\")\n",
    "\n",
    "clastering(deduper, data_for_training) # проводим кластеризацию и доразметку\n",
    "\n",
    "print(\"Работа завершена. Сохраняем настройки модели\")\n",
    "\n",
    "with open(settings_file, 'wb') as sf: #записываем настройки модели в файл\n",
    "    deduper.write_settings(sf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
